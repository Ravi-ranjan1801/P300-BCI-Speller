{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2c6df-e813-4b08-b495-d4993d70531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load saved data from Notebook-1\n",
    "eeg = np.load(\"../data/eeg.npy\")\n",
    "stim_code = np.load(\"../data/stim_code.npy\")\n",
    "stim_type = np.load(\"../data/stim_type.npy\")\n",
    "\n",
    "fs = 240\n",
    "print(eeg.shape, stim_code.shape, stim_type.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa62f2-1232-4fe4-8870-2758fc5e0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, fs, low=0.1, high=30):\n",
    "    b, a = signal.butter(4, [low/(fs/2), high/(fs/2)], btype=\"band\")\n",
    "    return signal.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "eeg_filt = bandpass_filter(eeg, fs)\n",
    "print(\"Filtered EEG shape:\", eeg_filt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e707f1-a848-4f6e-887d-90943fbff603",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_len = int(0.8 * fs)  # 800 ms\n",
    "epochs = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(stim_code)):\n",
    "    if stim_code[i] != 0:\n",
    "        start = i\n",
    "        end = i + epoch_len\n",
    "        if end < eeg_filt.shape[0]:\n",
    "            epochs.append(eeg_filt[start:end, :])\n",
    "            labels.append(stim_type[i])\n",
    "\n",
    "epochs = np.array(epochs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Epochs:\", epochs.shape)\n",
    "print(\"Labels:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61a01f-b186-42e1-8b1a-148228938aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (epochs, time, channels) → (epochs, channels, time, 1)\n",
    "X = np.transpose(epochs, (0, 2, 1))[..., np.newaxis]\n",
    "y = labels\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c67afb-14bd-4454-a52b-d1030d9d9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, stim_train, stim_test = train_test_split(\n",
    "    X, y, stim_code[stim_code != 0],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_test.shape, stim_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaca60c-4bd6-4ac6-8e9d-81999e90b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization,\n",
    "    Activation, AveragePooling2D,\n",
    "    Dropout, Flatten, Dense\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def EEGNet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(16, (1, 64), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"elu\")(x)\n",
    "    x = AveragePooling2D((1, 4))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = EEGNet(X_train.shape[1:])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256b161-381a-4b73-b73a-fc8dc6f80193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,          # 20 is correct\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c41edc-ce3d-4be3-a0a3-f777d25f0164",
   "metadata": {},
   "source": [
    "We trained for 20 epochs because the model converged before that point; validation accuracy saturated and further training risked overfitting without improving performance.\n",
    "In future work, we would use early stopping to automatically determine the optimal number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a4342-0ed3-43ca-892c-f05a46162959",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "y_prob = model.predict(X_test).ravel()\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"Test AUC:\", auc)\n",
    "\n",
    "cm = confusion_matrix(y_test, (y_prob > 0.5).astype(int))\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642bb2-21c2-438e-bb60-5b993788e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/p300_cnn.keras\")\n",
    "print(\"Model saved successfully in Keras format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b6a9-08f0-47fa-a957-c88ae0db42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities (NOT binary)\n",
    "y_prob = model.predict(X_test).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50296e-81e2-47de-8b9f-801550a719a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "labels = []\n",
    "epoch_stim_codes = []\n",
    "\n",
    "epoch_len = int(0.8 * fs)\n",
    "\n",
    "for i in range(len(stim_code)):\n",
    "    if stim_code[i] != 0:\n",
    "        start = i\n",
    "        end = i + epoch_len\n",
    "\n",
    "        if end < eeg_filt.shape[0]:\n",
    "            epochs.append(eeg_filt[start:end, :])\n",
    "            labels.append(stim_type[i])\n",
    "            epoch_stim_codes.append(stim_code[i])\n",
    "\n",
    "epochs = np.array(epochs)\n",
    "labels = np.array(labels)\n",
    "epoch_stim_codes = np.array(epoch_stim_codes)\n",
    "\n",
    "print(\"Epochs:\", epochs.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "print(\"Stim codes:\", epoch_stim_codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390b49c-ee21-499a-a7eb-cb6ec6a90fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.transpose(epochs, (0, 2, 1))[..., np.newaxis]\n",
    "y = labels\n",
    "stim_codes = epoch_stim_codes\n",
    "\n",
    "X_train, X_test, y_train, y_test, stim_train, stim_test = train_test_split(\n",
    "    X, y, stim_codes,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_test.shape, stim_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d15fb-bc71-4e76-b578-d77e199f579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_row_col(stim_codes, probs):\n",
    "    \"\"\"\n",
    "    stim_codes: array of stimulus codes (1–12)\n",
    "    probs: P300 probabilities for those flashes\n",
    "    \"\"\"\n",
    "    row_scores = np.zeros(6)\n",
    "    col_scores = np.zeros(6)\n",
    "\n",
    "    for code, p in zip(stim_codes, probs):\n",
    "        if 1 <= code <= 6:          # rows\n",
    "            row_scores[code - 1] += p\n",
    "        elif 7 <= code <= 12:       # columns\n",
    "            col_scores[code - 7] += p\n",
    "\n",
    "    row = np.argmax(row_scores)\n",
    "    col = np.argmax(col_scores)\n",
    "\n",
    "    return row, col, row_scores, col_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ffc2b-5f5e-4fa0-b967-2d0dfe92d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_size = 120\n",
    "\n",
    "stim_trial = stim_test[:trial_size]\n",
    "prob_trial = y_prob[:trial_size]\n",
    "\n",
    "row, col, r_scores, c_scores = decode_row_col(stim_trial, prob_trial)\n",
    "\n",
    "print(\"Predicted row:\", row)\n",
    "print(\"Predicted column:\", col)\n",
    "print(\"Row scores:\", r_scores)\n",
    "print(\"Column scores:\", c_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9b061-d3c0-4411-8034-7d0b2be4340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speller = np.array([\n",
    "    ['A','B','C','D','E','F'],\n",
    "    ['G','H','I','J','K','L'],\n",
    "    ['M','N','O','P','Q','R'],\n",
    "    ['S','T','U','V','W','X'],\n",
    "    ['Y','Z','1','2','3','4'],\n",
    "    ['5','6','7','8','9','_']\n",
    "])\n",
    "\n",
    "predicted_char = speller[row, col]\n",
    "print(\"Predicted character:\", predicted_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca28e4-ce04-4594-a349-dbb999d5dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_character_from_epochs(stim_codes, probs):\n",
    "    row_scores = np.zeros(6)\n",
    "    col_scores = np.zeros(6)\n",
    "\n",
    "    for code, p in zip(stim_codes, probs):\n",
    "        if 1 <= code <= 6:\n",
    "            row_scores[code - 1] += p\n",
    "        elif 7 <= code <= 12:\n",
    "            col_scores[code - 7] += p\n",
    "\n",
    "    row = np.argmax(row_scores)\n",
    "    col = np.argmax(col_scores)\n",
    "\n",
    "    return row, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7eb77-54f4-438c-8ae4-09eb19a95ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speller = np.array([\n",
    "    ['A','B','C','D','E','F'],\n",
    "    ['G','H','I','J','K','L'],\n",
    "    ['M','N','O','P','Q','R'],\n",
    "    ['S','T','U','V','W','X'],\n",
    "    ['Y','Z','1','2','3','4'],\n",
    "    ['5','6','7','8','9','_']\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1f36b-5340-4281-af79-67b4affb1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_word(stim_codes, probs, chars=5, flashes_per_char=120):\n",
    "    decoded = []\n",
    "    pointer = 0\n",
    "\n",
    "    for _ in range(chars):\n",
    "        stim_chunk = stim_codes[pointer:pointer + flashes_per_char]\n",
    "        prob_chunk = probs[pointer:pointer + flashes_per_char]\n",
    "\n",
    "        row, col = decode_character_from_epochs(stim_chunk, prob_chunk)\n",
    "        decoded.append(speller[row, col])\n",
    "\n",
    "        pointer += flashes_per_char\n",
    "\n",
    "    return ''.join(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb18b7a-379d-4235-ba51-ac8bb257bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_word = decode_word(\n",
    "    stim_test,\n",
    "    y_prob,\n",
    "    chars=5,\n",
    "    flashes_per_char=120\n",
    ")\n",
    "\n",
    "print(\"Decoded word:\", decoded_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca3bcb-52ca-4337-8324-dd0a95dea476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def live_p300_demo(stim_codes, probs, flashes_per_char=120, delay=0.05, max_chars=5):\n",
    "    row_scores = np.zeros(6)\n",
    "    col_scores = np.zeros(6)\n",
    "    flash_count = 0\n",
    "    char_count = 0\n",
    "\n",
    "    for code, p in zip(stim_codes, probs):\n",
    "        time.sleep(delay)\n",
    "\n",
    "        if 1 <= code <= 6:\n",
    "            row_scores[code - 1] += p\n",
    "        elif 7 <= code <= 12:\n",
    "            col_scores[code - 7] += p\n",
    "\n",
    "        flash_count += 1\n",
    "\n",
    "        if flash_count == flashes_per_char:\n",
    "            row = np.argmax(row_scores)\n",
    "            col = np.argmax(col_scores)\n",
    "            char = speller[row, col]\n",
    "\n",
    "            print(\"➡️ Spelled character:\", char)\n",
    "\n",
    "            row_scores[:] = 0\n",
    "            col_scores[:] = 0\n",
    "            flash_count = 0\n",
    "            char_count += 1\n",
    "\n",
    "            if char_count == max_chars:\n",
    "                print(\"✅ Demo finished\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be133e-b514-4794-ab57-379eddbd3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_p300_demo(stim_test, y_prob, max_chars=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89509c79-888b-4d4b-863c-fb64a6dd1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/X_test.npy\", X_test)\n",
    "np.save(\"../data/y_test.npy\", y_test)\n",
    "np.save(\"../data/stim_test.npy\", stim_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
